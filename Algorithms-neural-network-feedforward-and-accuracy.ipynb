{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms: neural network, feedforward, and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "The neural network algorithm  \n",
    "can be devided into three major parts:  \n",
    "feedforward, backpropagation, and update weights.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[0] ### 150\n",
    "\n",
    "y_oh = np.zeros((N, 3))\n",
    "y_oh[np.arange(N), y] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y =\n",
      "[0 0 1 1 2 2]\n",
      "\n",
      "y_oh =\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"y =\")\n",
    "print(y[::25])\n",
    "print()\n",
    "print(\"y_oh =\")\n",
    "print(y_oh[::25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(4, activation='sigmoid', input_shape=(4,)))\n",
    "### adding one more layer is not necessarily good\n",
    "# model.add(Dense(3, activation='sigmoid')) \n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /projects/17d9912b-1105-4c79-ad9b-b38a4f5c1fff/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 997us/step - loss: 1.0566 - accuracy: 0.5641\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 922us/step - loss: 0.8072 - accuracy: 0.7532\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 913us/step - loss: 0.6281 - accuracy: 0.8453\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 899us/step - loss: 0.5233 - accuracy: 0.9213\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 930us/step - loss: 0.4438 - accuracy: 0.9483\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 885us/step - loss: 0.3743 - accuracy: 0.9667\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 935us/step - loss: 0.3135 - accuracy: 0.9668\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 889us/step - loss: 0.2639 - accuracy: 0.9733\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 890us/step - loss: 0.2255 - accuracy: 0.9733\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 902us/step - loss: 0.1965 - accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4b0a0a72e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y_oh, steps_per_epoch=1000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2 = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1.shape = (4, 4)\n",
      "b1.shape = (4,)\n",
      "W2.shape = (4, 3)\n",
      "b2.shape = (3,)\n"
     ]
    }
   ],
   "source": [
    "print('W1.shape =', W1.shape)\n",
    "print('b1.shape =', b1.shape)\n",
    "print('W2.shape =', W2.shape)\n",
    "print('b2.shape =', b2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  If Keras or sklearn is not available for you  \n",
    "you may randomly initiate the weights  \n",
    "to do the exercises below.\n",
    "```Python\n",
    "W1 = np.random.arange(4,4)\n",
    "b1 = np.random.arange(4,)\n",
    "W2 = np.random.arange(4,3)\n",
    "b2 = np.random.arange(4,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward\n",
    "Feedforward sends the data through the network  \n",
    "and get the prediction.  \n",
    "\n",
    "If follows from some recurrsive formulas.\n",
    "1. $z_i = a_{i-1}W_i + b_i$ for $i=1,\\ldots$\n",
    "2. $a_i = \\sigma(z_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $a_0$ is the input.  \n",
    "That is, rows of `X`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each layer contains  \n",
    "a **weight** `Wi` and  \n",
    "a **bias** `bi`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **sigmoid function** is  $\\frac{1}{1 + e^{-x}}$.  \n",
    "When it is applied to an array,  \n",
    "the function is applied to each entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **activation function** refers to  \n",
    "the sigmoid function and the softmax function.  \n",
    "\n",
    "The softmax function matters  \n",
    "only for the training part,  \n",
    "so we ignore it here.  \n",
    "\n",
    "Let's use $\\sigma$ for the activation function.  \n",
    "It varies from each layer,  \n",
    "though here it is only the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "`0 -> [1, 0, 0]`  \n",
    "`1 -> [0, 1, 0]`  \n",
    "`2 -> [0, 0, 1]`  \n",
    "In one-hot encoding,  \n",
    "the distance between two categories  \n",
    "is the same for every pair of categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to transform  \n",
    "the label to one-hot encoding  \n",
    "is by **fancy indexing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(9).reshape(3,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 6, 1, 4, 7, 2, 5, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[[0,1,2,0,1,2,0,1,2], [0,0,0,1,1,1,2,2,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[np.arange(3), np.arange(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now review how we did that \n",
    "\n",
    "```Python\n",
    "N = X.shape[0] ### 150\n",
    "\n",
    "y_oh = np.zeros((N, 3))\n",
    "y_oh[np.arange(N), y] = 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "When $a_2$ (the output of the last layer)  \n",
    "is generated,   \n",
    "the predicted answer is `np.argmax(a2)`.  \n",
    "That is, the index for the maximum entry.  \n",
    "(Or the one-hot encoding of `np.argmax(a2)`,  \n",
    "depending on the structure of the target.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of softmax,  \n",
    "`np.argmax(a2) == np.argmax(z2)`,  \n",
    "so it is enough to deal with `np.argmax(z2)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "Let `a0 = X[0]`, the first row of `X`.  \n",
    "Compute `z1 = np.dot(a0, W1) + b1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "Use `lambda` syntax to write the sigmoid function.  \n",
    "Then define `sigmoid` as the vectorized sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "Compute `a1 = sigmoid(z1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "Compute `z2 = np.dot(a1, W2) + b2`.  \n",
    "(As discussed, let's not compute `a2`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "Write a function `one_hot(k)`  \n",
    "that returns an array of shape `(3,)`  \n",
    "with a `1` at index `k` while  \n",
    "other entries are `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "Use `np.all`  \n",
    "to tell whether  \n",
    "`one_hot(np.argmax(z2))` and `y_oh[0]`  \n",
    "are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "Combine everything above.  \n",
    "Use `for` loop to iterate every row in `X`  \n",
    "and compute the accuracy of the prediction.  \n",
    "\n",
    "Your answer should be the same as the output of Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "Apply the idea of vectorization as possible.  \n",
    "Can you generate the answer of the previous question  \n",
    "without using a `for` loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample code for accuracy (without `for` loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "### vectorized sigmoid function\n",
    "sigmoid = np.vectorize(lambda x: 1 / (1+np.exp(-x)))\n",
    "\n",
    "z1 = np.dot(X, W1) + b1\n",
    "a1 = sigmoid(z1)\n",
    "z2 = np.dot(a1, W2) + b2\n",
    "### again, computing a2 is not necessary in this case\n",
    "\n",
    "ans_label = np.argmax(z2, axis=1)\n",
    "\n",
    "### create one-hot encoding\n",
    "N = X.shape[0]\n",
    "ans_oh = np.zeros((N, 3))\n",
    "ans_oh[np.arange(N), ans_label] = 1\n",
    "acc = np.all(ans_oh == y_oh, axis=1).sum() / N\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
